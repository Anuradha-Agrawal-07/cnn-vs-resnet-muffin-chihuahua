{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF0i-llvr46u",
        "outputId": "20f4eac1-a1b8-4196-b2a1-09f0a85b9b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet18\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "kWWB8UiuUink"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYWoEiF5UimR",
        "outputId": "90e8dbe4-3c5d-4ec0-cd52-3c5296d89c03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "fHnLDj08UpxI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/data/train\"\n",
        "test_dir  = \"/content/drive/MyDrive/data/test\"\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "test_dataset  = ImageFolder(test_dir,  transform=transform)\n"
      ],
      "metadata": {
        "id": "wo-7McpFUqOu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "D2j5drB2Uqkg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_to_idx\n"
      ],
      "metadata": {
        "id": "7h0lBFSIUqyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9674f01d-79cd-4853-a8cd-213e3e51b95c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chihuahua': 0, 'muffin': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# Replace final layer (1000 â†’ 2)\n",
        "model.fc = nn.Linear(512, 2)\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "iM0dOUzOUrAI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n"
      ],
      "metadata": {
        "id": "Vmge2ITXUrPc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "HN7U3c6NUrhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39c0aaf-5aba-43ed-add9-8be65b8844e4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 12.2985\n",
            "Epoch 2/5, Loss: 7.6657\n",
            "Epoch 3/5, Loss: 5.0507\n",
            "Epoch 4/5, Loss: 4.1071\n",
            "Epoch 5/5, Loss: 3.7574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(\"Test Accuracy:\", correct / total)\n"
      ],
      "metadata": {
        "id": "n1ou5bbTUr5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab86445a-a56b-456f-9670-e4935ebb6939"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9493243243243243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"chihuahua\", \"muffin\"]))\n"
      ],
      "metadata": {
        "id": "kh7zK5AbUsEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ed9403-fc4f-469e-c51a-fdefbfeff9b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[582  58]\n",
            " [  2 542]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   chihuahua       1.00      0.91      0.95       640\n",
            "      muffin       0.90      1.00      0.95       544\n",
            "\n",
            "    accuracy                           0.95      1184\n",
            "   macro avg       0.95      0.95      0.95      1184\n",
            "weighted avg       0.95      0.95      0.95      1184\n",
            "\n"
          ]
        }
      ]
    }
  ]
}